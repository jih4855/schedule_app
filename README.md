# AI Multi-Agent Toolkit

<div align="center">
  <img src="docs/image.png" alt="AI Multi-Agent Toolkit" width="800"/>
</div>

Python ê¸°ë°˜ LLM ì—ì´ì „íŠ¸ ê°œë°œì„ ìœ„í•œ ë„êµ¬ëª¨ìŒê³¼ ì‹¤ìš© ì˜ˆì œì…ë‹ˆë‹¤. ì—¬ëŸ¬ LLM í”„ë¡œë°”ì´ë” í†µí•©, ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜, Discord ì—°ë™ ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.

> **ğŸ“š ìš©ë„:** ì´ í”„ë¡œì íŠ¸ëŠ” AI ë° LLM ê¸°ìˆ  í•™ìŠµ, í”„ë¡œí† íƒ€ì… ê°œë°œ, ìŠ¤í¬ë¦½íŠ¸ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

**ğŸ“– ë¬¸ì„œ:** https://jih4855.github.io/AI-Multi-Agent-Toolkit/
**ğŸ“ Repository:** https://github.com/jih4855/AI-Multi-Agent-Toolkit

## ì£¼ìš” ê¸°ëŠ¥

- **ë©€í‹° LLM ì§€ì›**: Ollama, OpenAI, Google Gemini í†µí•©
- **ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ**: ë‹¨ì¼/ë©€í‹° ì—ì´ì „íŠ¸ íŒ¨í„´ ì§€ì›
- **ìŒì„± ì²˜ë¦¬**: Whisper ê¸°ë°˜ STT (Speech-to-Text)
- **Discord ì—°ë™**: ì›¹í›…ì„ í†µí•œ ë©”ì‹œì§€ ì „ì†¡ (ì²­í¬ ë¶„í•  ì§€ì›)
- **ëŒ€í™” ê¸°ì–µ**: SQLite ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
- **ë©€í‹°ëª¨ë‹¬ ì§€ì›**: ë¹„ì „ + ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ì„
- **ë¬¸ì„œí™”**: ë‹¤í¬ í…Œë§ˆ HTML ë¬¸ì„œ ì œê³µ

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- Python 3.10 ì´ìƒ
- pip (íŒ¨í‚¤ì§€ ê´€ë¦¬ì)
- ffmpeg (ìŒì„± ì²˜ë¦¬ ì‹œ í•„ìš”, ì„ íƒì‚¬í•­)

## ì„¤ì¹˜ ë°©ë²•

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone https://github.com/jih4855/AI-Multi-Agent-Toolkit.git
cd AI-Multi-Agent-Toolkit
```

### 2. ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

### 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
# .env.exampleì„ .envë¡œ ë³µì‚¬
cp .env.example .env

# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ì‹¤ì œ API í‚¤ë¡œ êµì²´
# GOOGLE_API_KEY=your_google_api_key_here
# OPENAI_API_KEY=your_openai_api_key_here
# DISCORD_WEBHOOK_URL=your_discord_webhook_url_here
```

**ì°¸ê³ :** Ollama ì‚¬ìš© ì‹œì—ëŠ” API í‚¤ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ë¹ ë¥¸ ì‹œì‘

### ê¸°ë³¸ LLM ì—ì´ì „íŠ¸ ì‚¬ìš©
```python
from module.llm_agent import LLM_Agent

# Ollama ì‚¬ìš© (ë¡œì»¬, API í‚¤ ë¶ˆí•„ìš”)
agent = LLM_Agent(model_name="gemma:2b", provider="ollama")
response = agent.generate_response(
    system_prompt="ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤.",
    user_message="ì•ˆë…•í•˜ì„¸ìš”, ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”."
)
print(response)
```

### í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ API ì—°ë™
```python
import os
from dotenv import load_dotenv
from module.llm_agent import LLM_Agent

load_dotenv()

# Google Gemini ì‚¬ìš©
agent = LLM_Agent(
    model_name="gemini-2.5-flash",
    provider="genai",
    api_key=os.getenv("GOOGLE_API_KEY")
)

response = agent(
    system_prompt="You are a helpful assistant.",
    user_message="Explain machine learning in simple terms."
)
print(response)
```

## ì‚¬ìš© ì˜ˆì œ

### 1. ë©€í‹° ì—ì´ì „íŠ¸ í™œìš©í•˜ê¸°

```python
from module.llm_agent import LLM_Agent

system_prompt = "You are a helpful assistant."
agent1_user_prompt = "ë¦¬ëˆ…ìŠ¤ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
agent2_user_prompt = "ì•ì„  ë‹µë³€ì„ ì½ê³  ë‚´ìš©ì„ ë³´ì¶©í•´ ì£¼ì„¸ìš”"

# ë³µìˆ˜ì˜ ì—ì´ì „íŠ¸ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
multi_agent = LLM_Agent(model_name="gemma3n", provider="ollama")
agent1 = multi_agent(system_prompt, agent1_user_prompt, task=None)
agent2 = multi_agent(system_prompt, agent2_user_prompt, task=None, multi_agent_response=agent1)

print("Agent 1 Response:", agent1)
print("Agent 2 Response:", agent2)
```

### 2. ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ í†µí•©í•˜ê¸°

```python
from module.llm_agent import LLM_Agent

# ê° ì—ì´ì „íŠ¸ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸, ì‘ì—…ì„ ì •ì˜í•©ë‹ˆë‹¤.
multi_agent_tasks = {
    "Agent 1": "ë„ì‹œì—ì„œ ë°œìƒí•˜ëŠ” í™˜ê²½ ë¬¸ì œ(ëŒ€ê¸°, ìˆ˜ì§ˆ, ì“°ë ˆê¸° ë“±)ë¥¼ ì •ë¦¬í•˜ê³ , ê°€ì¥ ì‹œê¸‰í•œ ê³¼ì œë¥¼ ì œì‹œí•œë‹¤.",
    "Agent 2": "ì¹œí™˜ê²½ êµí†µìˆ˜ë‹¨(ëŒ€ì¤‘êµí†µ, ìì „ê±°, ì „ê¸°ì°¨ ë“±)ì„ ê¸°ë°˜ìœ¼ë¡œ ì§€ì† ê°€ëŠ¥í•œ êµí†µ ì¸í”„ë¼ ê³„íšì„ ì œì•ˆí•œë‹¤.",
    "Agent 3": "ì¬ìƒì—ë„ˆì§€(íƒœì–‘ê´‘, í’ë ¥, ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ ë“±)ë¥¼ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ì¸ ì—ë„ˆì§€ ê³µê¸‰ ë°©ì•ˆì„ ì„¤ê³„í•œë‹¤.",
    "Agent 4": "ë„ì‹œ ê³µê°„ êµ¬ì¡°(ê³µì›, ì£¼ê±°, ìƒì—…ì§€êµ¬ ë°°ì¹˜ ë“±)ë¥¼ ìµœì í™”í•œë‹¤."
}

multi_agent_system_prompts = {
    "Agent 1": "ë‹¹ì‹ ì€ í™˜ê²½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë„ì‹œì˜ í™˜ê²½ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³ , ê°€ì¥ ì‹œê¸‰í•œ ë¬¸ì œë¥¼ ì œì‹œí•˜ì„¸ìš”.",
    "Agent 2": "ë‹¹ì‹ ì€ êµí†µ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§€ì† ê°€ëŠ¥í•œ êµí†µ ì¸í”„ë¼ ê³„íšì„ ì œì•ˆí•˜ì„¸ìš”.",
    "Agent 3": "ë‹¹ì‹ ì€ ì—ë„ˆì§€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¬ìƒì—ë„ˆì§€ë¥¼ í™œìš©í•œ ì—ë„ˆì§€ ê³µê¸‰ ë°©ì•ˆì„ ì„¤ê³„í•˜ì„¸ìš”.",
    "Agent 4": "ë‹¹ì‹ ì€ ë„ì‹œ ê³„íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë„ì‹œ ê³µê°„ êµ¬ì¡°ë¥¼ ìµœì í™”í•˜ëŠ” ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”."
}

user_prompts = {
    "Agent 1": "ë„ì‹œì—ì„œ ë°œìƒí•˜ëŠ” í™˜ê²½ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³ , ê°€ì¥ ì‹œê¸‰í•œ ë¬¸ì œë¥¼ ì œì‹œí•˜ì„¸ìš”.",
    "Agent 2": "ì§€ì† ê°€ëŠ¥í•œ êµí†µ ì¸í”„ë¼ ê³„íšì„ ì œì•ˆí•˜ì„¸ìš”.",
    "Agent 3": "ì¬ìƒì—ë„ˆì§€ë¥¼ í™œìš©í•œ ì—ë„ˆì§€ ê³µê¸‰ ë°©ì•ˆì„ ì„¤ê³„í•˜ì„¸ìš”.",
    "Agent 4": "ë„ì‹œ ê³µê°„ êµ¬ì¡°ë¥¼ ìµœì í™”í•˜ëŠ” ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”."
}

order = ["Agent 1", "Agent 2", "Agent 3", "Agent 4"]

multi_agent = LLM_Agent(model_name="gemini-2.5-flash", provider="genai", api_key="your_api_key")

agent_responses = {
    name: multi_agent(multi_agent_system_prompts[name], user_prompts[name], multi_agent_tasks[name])
    for name in order
}

response_list = [agent_responses[name] for name in order]

multi_agent_responses = multi_agent(
    "ë‹¹ì‹ ì€ ë„ì‹œ ê³„íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§€ì† ê°€ëŠ¥í•œ ë„ì‹œ ì„¤ê³„ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.",
    "ë‹¤ìŒì€ ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ì˜ê²¬ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ìš”ì•½ ë° í†µí•©ëœ ì§€ì† ê°€ëŠ¥í•œ ë„ì‹œ ì„¤ê³„ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.",
    "ìµœì¢… ìš”ì•½ ë° í†µí•©ëœ ì§€ì† ê°€ëŠ¥í•œ ë„ì‹œ ì„¤ê³„ ë°©ì•ˆì„ ì œì‹œí•œë‹¤.",
    response_list
)

print("Agent 1 Response:", agent_responses["Agent 1"])
print("Agent 2 Response:", agent_responses["Agent 2"])
print("Agent 3 Response:", agent_responses["Agent 3"])
print("Agent 4 Response:", agent_responses["Agent 4"])
print("Multi-Agent Responses:", multi_agent_responses)
```

### 3. LLM ì—ì´ì „íŠ¸ì— ê¸°ì–µë ¥ ë¶™ì´ê¸°

```python
import dotenv
import os
dotenv.load_dotenv()

# LLM_Agent ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm = LLM_Agent(model_name="gemini-2.5-flash", provider="genai", api_key=os.getenv("GENAI_API_KEY"), max_history=10)

# ëŒ€í™” ë£¨í”„ ì˜ˆì‹œ
while True:
    user_input = input("You: ")
    response = llm(system_prompt="You are a helpful assistant.", user_message=user_input, memory=True)
    print("Assistant:", response)

    if user_input.lower() in ['exit', 'quit']:
        break
```

### 4. ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„í•˜ê¸°

```python
import os
from dotenv import load_dotenv
from module.llm_agent import Multi_modal_agent

load_dotenv()

# ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ ìƒì„±
agent = Multi_modal_agent(
    model_name="gemini-2.5-flash",
    provider="genai",
    api_key=os.getenv("GOOGLE_API_KEY")
)

# êµ¬ì¡°í™”ëœ JSON ì¶œë ¥ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„
response = agent(
    system_prompt="""ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì„¸ìš”.
    ë‹¤ìŒ JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {
        "extracted_text": "ì´ë¯¸ì§€ì—ì„œ ë°œê²¬ëœ í…ìŠ¤íŠ¸ ë‚´ìš©",
        "confidence": "high/medium/low",
        "language": "ê°ì§€ëœ ì–¸ì–´",
        "additional_notes": "ì¶”ê°€ ê´€ì°° ì‚¬í•­"
    }""",
    user_message="ì´ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•´ì£¼ì„¸ìš”.",
    image_path="path/to/your/image.jpg"
)

print("ë¶„ì„ ê²°ê³¼:", response)
```

### 5. Discordë¡œ ë©”ì‹œì§€ ë³´ë‚´ê¸°

```python
from module.discord import Send_to_discord
from module.llm_agent import LLM_Agent

model_name = 'gemma3:12b'
system_prompt = 'ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤. ì´ìš©ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.'
user_prompt = 'í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?'
provider = 'ollama'

agent = LLM_Agent(model_name, provider, api_key=None)
response = agent(system_prompt, user_prompt, task=None)

discord = Send_to_discord(base_url="your_discord_webhook_url")
discord.send_message(response)
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
agent/
â”œâ”€â”€ module/                 # í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â”œâ”€â”€ llm_agent.py       # LLM ì—ì´ì „íŠ¸ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ audio_tool.py      # ìŒì„± ì²˜ë¦¬ ë„êµ¬
â”‚   â”œâ”€â”€ discord.py         # Discord ì—°ë™
â”‚   â”œâ”€â”€ memory.py          # ëŒ€í™” ê¸°ì–µ ê´€ë¦¬
â”‚   â””â”€â”€ text_tool.py       # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ test/                  # ì‚¬ìš© ì˜ˆì œ ë° í…ŒìŠ¤íŠ¸
â”œâ”€â”€ docs/                  # HTML ë¬¸ì„œ
â”‚   â””â”€â”€ index.html         # ìƒì„¸ ì‚¬ìš©ë²• ê°€ì´ë“œ
â”œâ”€â”€ .env.example           # í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ requirements.txt       # Python ì˜ì¡´ì„±
â””â”€â”€ README.md             # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## API í‚¤ ì„¤ì •

### Google Gemini API
1. [Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ API í‚¤ ë°œê¸‰
2. `.env` íŒŒì¼ì— `GOOGLE_API_KEY=your_key` ì¶”ê°€

### OpenAI API
1. [OpenAI Platform](https://platform.openai.com/api-keys)ì—ì„œ API í‚¤ ë°œê¸‰
2. `.env` íŒŒì¼ì— `OPENAI_API_KEY=your_key` ì¶”ê°€

### Discord ì›¹í›… (ì„ íƒì‚¬í•­)
1. Discord ì„œë²„ ì„¤ì • > ì—°ë™ > ì›¹í›„í¬ì—ì„œ ìƒì„±
2. `.env` íŒŒì¼ì— `DISCORD_WEBHOOK_URL=your_webhook_url` ì¶”ê°€

## ë¬¸ì„œ

ìì„¸í•œ ì‚¬ìš©ë²•ê³¼ ì˜ˆì œëŠ” ì˜¨ë¼ì¸ ë¬¸ì„œì—ì„œ í™•ì¸í•˜ì„¸ìš”:

**ğŸ“– ì˜¨ë¼ì¸ ë¬¸ì„œ:** https://jih4855.github.io/AI-Multi-Agent-Toolkit/

ë˜ëŠ” ë¡œì»¬ì—ì„œ `docs/index.html`ì„ ë¸Œë¼ìš°ì €ë¡œ ì—´ì–´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# ë¸Œë¼ìš°ì €ì—ì„œ ë¡œì»¬ ë¬¸ì„œ ì—´ê¸°
open docs/index.html    # macOS
start docs/index.html   # Windows
xdg-open docs/index.html # Linux
```

**ë¬¸ì„œ ì£¼ìš” ë‚´ìš©:**
- ë‹¨ê³„ë³„ ì„¤ì¹˜ ê°€ì´ë“œ ë° í™˜ê²½ ì„¤ì •
- ê¸°ë³¸ LLM ì—ì´ì „íŠ¸ ì‚¬ìš©ë²•
- ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì„± ë°©ë²•
- ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ ì‹¤ìŠµ
- Discord ë©”ì‹œì§€ ì „ì†¡ ë° ì²­í¬ ë¶„í• 
- ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê¸°ì–µ ê¸°ëŠ¥
- íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë° ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

## í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

**ModuleNotFoundError**
```bash
# í•´ê²°ë°©ë²•: ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸ í›„ ì˜ì¡´ì„± ì¬ì„¤ì¹˜
pip install -r requirements.txt
```

**API í‚¤ ê´€ë ¨ ì˜¤ë¥˜**
```bash
# í•´ê²°ë°©ë²•: .env íŒŒì¼ ì„¤ì • í™•ì¸
cat .env  # ì„¤ì •ëœ í™˜ê²½ ë³€ìˆ˜ í™•ì¸
```

**Ollama ì—°ê²° ì˜¤ë¥˜**
```bash
# í•´ê²°ë°©ë²•: Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ í™•ì¸
ollama list  # ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
```

**ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜**
```bash
# í•´ê²°ë°©ë²•: ffmpeg ì„¤ì¹˜
# Windows (Chocolatey):
choco install ffmpeg

# macOS (Homebrew):
brew install ffmpeg

# Ubuntu/Debian:
sudo apt install ffmpeg

# ì„¤ì¹˜ í™•ì¸:
ffmpeg -version
```

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ììœ ë¡­ê²Œ ì‚¬ìš©, ìˆ˜ì •, ë°°í¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```
MIT License

Copyright (c) 2024 AI Multi-Agent Toolkit

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ê¸°ì—¬í•˜ê¸°

ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¡œì„œ ì—¬ëŸ¬ë¶„ì˜ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!

1. í”„ë¡œì íŠ¸ë¥¼ í¬í¬í•˜ì„¸ìš”
2. ê¸°ëŠ¥ ë¸Œëœì¹˜ë¥¼ ìƒì„±í•˜ì„¸ìš” (`git checkout -b feature/AmazingFeature`)
3. ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•˜ì„¸ìš” (`git commit -m 'Add some AmazingFeature'`)
4. ë¸Œëœì¹˜ì— í‘¸ì‹œí•˜ì„¸ìš” (`git push origin feature/AmazingFeature`)
5. Pull Requestë¥¼ ìƒì„±í•˜ì„¸ìš”

## ë¬¸ì˜ ë° ì§€ì›

- GitHub Issues: ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ê¸°ëŠ¥ ìš”ì²­
- GitHub Discussions: ì¼ë°˜ì ì¸ ì§ˆë¬¸ ë° í† ë¡ 
